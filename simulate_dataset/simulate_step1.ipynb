{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/wangpengxiao/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data2/wangpengxiao/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1153: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "from PIL import Image\n",
    "import os.path as osp\n",
    "import glob  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from helper import *\n",
    "\n",
    "mod = load_model('mod.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_path = \"/data4/wangpengxiao/danbooru2017/original\"\n",
    "source_img_path = glob.glob(osp.join(source_data_path,'*/*.jpg'))\n",
    "source_img_path += glob.glob(osp.join(source_data_path,'*/*.png'))\n",
    "source_img_path = sorted(source_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1291861\n"
     ]
    }
   ],
   "source": [
    "print(len(source_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2318/1291862 [00:21<3:22:56, 105.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm /data4/wangpengxiao/danbooru2017/original/0000/429000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2502/1291862 [00:23<3:18:00, 108.53it/s]"
     ]
    }
   ],
   "source": [
    "# for path in tqdm(source_img_path):\n",
    "#     try:\n",
    "#         Image.open(path)\n",
    "#     except:\n",
    "#         os.system(\"rm \"+path)   \n",
    "#         print(\"rm \"+path)\n",
    "\n",
    "# source_img = np.array(source_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomCenterCrop(path, min_size, max_size):\n",
    "    '''\n",
    "    simulate dataset step 1: Crop Randomly\n",
    "    '''\n",
    "    size = np.random.randint(min_size, max_size)\n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    top = np.random.randint(0, h - size)\n",
    "    left = np.random.randint(0, w - size)\n",
    "\n",
    "    return img[top:size+top, left:size+left, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(path, min_patch_size, max_patch_size):\n",
    "    '''\n",
    "    get patch from clothes\n",
    "    '''\n",
    "    patch_size = np.random.randint(min_patch_size, max_patch_size)\n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    center_h = h/2\n",
    "    center_w = w/2\n",
    "    \n",
    "    patch = img[int(center_h - patch_size/2):int(center_h + patch_size/2), int(center_w - patch_size/2):int(center_w + patch_size/2), :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detecton(path):\n",
    "    '''\n",
    "    get sketch\n",
    "    '''\n",
    "    from_mat = cv2.imread(path)\n",
    "    width = float(from_mat.shape[1])\n",
    "    height = float(from_mat.shape[0])\n",
    "    new_width = 0\n",
    "    new_height = 0\n",
    "    if (width > height):\n",
    "        from_mat = cv2.resize(from_mat, (512, int(512 / width * height)), interpolation=cv2.INTER_AREA)\n",
    "        new_width = 512\n",
    "        new_height = int(512 / width * height)\n",
    "    else:\n",
    "        from_mat = cv2.resize(from_mat, (int(512 / height * width), 512), interpolation=cv2.INTER_AREA)\n",
    "        new_width = int(512 / height * width)\n",
    "        new_height = 512\n",
    "    from_mat = from_mat.transpose((2, 0, 1))\n",
    "    light_map = np.zeros(from_mat.shape, dtype=np.float)\n",
    "    for channel in range(3):\n",
    "        light_map[channel] = get_light_map_single(from_mat[channel])\n",
    "    light_map = normalize_pic(light_map)\n",
    "    light_map = resize_img_512_3d(light_map)\n",
    "    line_mat = mod.predict(light_map, batch_size=1)\n",
    "    line_mat = line_mat.transpose((3, 1, 2, 0))[0]\n",
    "    line_mat = line_mat[0:int(new_height), 0:int(new_width), :]\n",
    "    #sketchKeras_colored = show_active_img_and_save('sketchKeras_colored', line_mat, 'sketchKeras_colored.jpg')\n",
    "    line_mat = np.amax(line_mat, 2)\n",
    "    #sketchKeras_enhanced = show_active_img_and_save_denoise_filter2('sketchKeras_enhanced', line_mat, 'sketchKeras_enhanced.jpg')\n",
    "    #sketchKeras_pured = show_active_img_and_save_denoise_filter('sketchKeras_pured', line_mat, 'sketchKeras_pured.jpg')\n",
    "    sketchKeras = show_active_img_and_save_denoise('sketchKeras', line_mat, 'sketchKeras.jpg')\n",
    "    #cv2.waitKey(0)\n",
    "    return sketchKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(path):\n",
    "    '''\n",
    "    提取衣服的mask\n",
    "    返回numpy数组\n",
    "    '''\n",
    "    from linefiller.trappedball_fill import trapped_ball_fill_multi, flood_fill_multi, mark_fill, build_fill_map, merge_fill, \\\n",
    "    show_fill_map\n",
    "    from linefiller.thinning import thinning\n",
    "\n",
    "    im = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    ret, binary = cv2.threshold(im, 220, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    fills = []\n",
    "    result = binary\n",
    "\n",
    "    fill = trapped_ball_fill_multi(result, 3, method='max')\n",
    "    fills += fill\n",
    "    result = mark_fill(result, fill)\n",
    "\n",
    "    fill = trapped_ball_fill_multi(result, 2, method=None)\n",
    "    fills += fill\n",
    "    result = mark_fill(result, fill)\n",
    "\n",
    "    fill = trapped_ball_fill_multi(result, 1, method=None)\n",
    "    fills += fill\n",
    "    result = mark_fill(result, fill)\n",
    "\n",
    "    fill = flood_fill_multi(result)\n",
    "    fills += fill\n",
    "\n",
    "    fillmap = build_fill_map(result, fills)\n",
    "\n",
    "    fillmap = merge_fill(fillmap)\n",
    "\n",
    "\n",
    "    for i in range(len(fillmap[:,0])):\n",
    "        for j in range(len(fillmap[0,:])):\n",
    "            if fillmap[i,j] == 1:\n",
    "                fillmap[i,j] = 0\n",
    "            else:\n",
    "                fillmap[i,j] = 1\n",
    "    \n",
    "    return fillmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1998/1291861 [10:01<107:52:26,  3.32it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c2f15b73b540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msketch_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msketch_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_detecton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msketch_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msketch_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1645597c528a>\u001b[0m in \u001b[0;36medge_detecton\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlight_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_pic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlight_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlight_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_img_512_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlight_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mline_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlight_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mline_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mline_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1571\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1573\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1201\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sketch_path = \"/data4/wangpengxiao/danbooru2017/original_sketch\"\n",
    "os.mkdir(sketch_path)\n",
    "for path in  tqdm(source_img_path):\n",
    "    sketch_img = edge_detecton(path)\n",
    "    cv2.imwrite(osp.join(sketch_path, osp.basename(path)), sketch_img)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_crop_path = \"/data4/wangpengxiao/zalando_random_crop\"\n",
    "patch_path = \"/data4/wangpengxiao/zalando_center_patch\"\n",
    "sketch_path = \"/data4/wangpengxiao/zalando_sketch\"\n",
    "for path in  tqdm(source_img_path):\n",
    "    try:\n",
    "    #step1_1： make randomly croped rectangular patches \n",
    "        r_im = RandomCenterCrop(path, 64, 256)\n",
    "        cv2.imwrite(osp.join(random_crop_path, osp.basename(path)), r_im)\n",
    "    #step1_2： make randomly croped rectangular patches    \n",
    "        p_im = get_patch(path, 64, 256)\n",
    "        cv2.imwrite(osp.join(patch_path, osp.basename(path)), p_im)\n",
    "\n",
    "        sketch_img = edge_detecton(path)\n",
    "        cv2.imwrite(osp.join(sketch_path, osp.basename(path)), sketch_img)\n",
    "    except:\n",
    "        os.system(\"rm \"+path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linefiller.trappedball_fill import trapped_ball_fill_multi, flood_fill_multi, mark_fill, build_fill_map, merge_fill, \\\n",
    "    show_fill_map\n",
    "from linefiller.thinning import thinning\n",
    "def get_region_picture(path):\n",
    "    '''\n",
    "    获取不规则形状的图片，背景是黑色0，方便rotate\n",
    "    '''\n",
    "    im = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    ret, binary = cv2.threshold(im, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    fills = []\n",
    "    result = binary\n",
    "\n",
    "    fill = trapped_ball_fill_multi(result, 3, method='max')\n",
    "    fills += fill\n",
    "    result = mark_fill(result, fill)\n",
    "\n",
    "    fill = trapped_ball_fill_multi(result, 2, method=None)\n",
    "    fills += fill\n",
    "    result = mark_fill(result, fill)\n",
    "\n",
    "    fill = trapped_ball_fill_multi(result, 1, method=None)\n",
    "    fills += fill\n",
    "    result = mark_fill(result, fill)\n",
    "\n",
    "    fill = flood_fill_multi(result)\n",
    "    fills += fill\n",
    "\n",
    "    fillmap = build_fill_map(result, fills)\n",
    "\n",
    "    fillmap = merge_fill(fillmap)\n",
    "\n",
    "    fillmap = thinning(fillmap)\n",
    "\n",
    "    #获得region mask\n",
    "    for i in range(len(fillmap[:,0])):\n",
    "        for j in range(len(fillmap[0,:])):\n",
    "            if fillmap[i,j] == 0:\n",
    "                fillmap[i,j] = 1\n",
    "            else:\n",
    "                fillmap[i,j] = 0\n",
    "    #获得region picture    \n",
    "    im = cv2.imread(path)\n",
    "#     plt.imshow(im)\n",
    "    rgb_fillmap = np.zeros(im.shape)\n",
    "    rgb_fillmap[:,:,0] = fillmap\n",
    "    rgb_fillmap[:,:,1] = fillmap\n",
    "    rgb_fillmap[:,:,2] = fillmap\n",
    "    im = im * rgb_fillmap\n",
    "    \n",
    "    return im.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1291861 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/1291861 [00:02<907:39:08,  2.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/1291861 [00:24<4404:23:15, 12.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 3/1291861 [00:27<3347:31:03,  9.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 4/1291861 [00:31<2845:32:44,  7.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 5/1291861 [00:40<2904:52:21,  8.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 6/1291861 [00:53<3195:43:03,  8.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 7/1291861 [01:07<3463:32:02,  9.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 8/1291861 [01:19<3570:45:10,  9.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 9/1291861 [01:41<4029:14:07, 11.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 10/1291861 [02:14<4824:11:38, 13.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 11/1291861 [02:36<5091:30:44, 14.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 12/1291861 [02:42<4846:45:21, 13.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 13/1291861 [02:50<4696:21:59, 13.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 14/1291861 [03:06<4777:32:57, 13.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 15/1291861 [03:36<5168:41:14, 14.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 16/1291861 [03:48<5128:58:07, 14.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 17/1291861 [04:10<5290:36:30, 14.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 18/1291861 [04:12<5030:23:08, 14.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 19/1291861 [04:55<5580:40:18, 15.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 20/1291861 [06:38<7145:07:20, 19.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 21/1291861 [07:20<7532:04:28, 20.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 22/1291861 [08:35<8412:27:24, 23.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 23/1291861 [10:49<10128:49:58, 28.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 24/1291861 [11:21<10187:27:25, 28.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 25/1291861 [11:32<9935:20:54, 27.69s/it] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 26/1291861 [11:52<9836:43:42, 27.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 27/1291861 [12:01<9586:00:51, 26.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 28/1291861 [12:16<9436:39:40, 26.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 29/1291861 [12:35<9345:09:28, 26.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 30/1291861 [13:02<9363:47:58, 26.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 31/1291861 [13:17<9234:14:25, 25.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 32/1291861 [13:28<9061:11:26, 25.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 33/1291861 [13:35<8872:59:15, 24.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 34/1291861 [15:14<9647:42:47, 26.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 35/1291861 [38:44<23833:52:24, 66.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 36/1291861 [38:55<23278:18:22, 64.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 37/1291861 [39:05<22749:22:40, 63.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 38/1291861 [41:23<23454:09:04, 65.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 39/1291861 [41:40<23009:18:52, 64.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 40/1291861 [51:07<27517:33:57, 76.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 41/1291861 [51:19<26952:44:07, 75.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b42b9a0089cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mregion_picture_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/data4/wangpengxiao/danbooru2017/original_region_picture\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrp_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_region_picture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_picture_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrp_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-01b0ffa9cc5c>\u001b[0m in \u001b[0;36mget_region_picture\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmark_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mfill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflood_fill_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mfills\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GANs/style2paints_V3/linefiller/trappedball_fill.py\u001b[0m in \u001b[0;36mflood_fill_multi\u001b[0;34m(image, max_iter)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0munfill_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfill_area\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mfilled_area\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilled_area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "region_picture_path = \"/data4/wangpengxiao/danbooru2017/original_region_picture\"\n",
    "for path in tqdm(source_img_path):\n",
    "    rp_im = get_region_picture(path)\n",
    "    cv2.imwrite(osp.join(region_picture_path, osp.basename(path)), rp_im)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_crop_path = \"/data4/wangpengxiao/zalando_random_crop\"\n",
    "patch_path = \"/data4/wangpengxiao/zalando_center_patch\"\n",
    "sketch_path = \"/data4/wangpengxiao/zalando_sketch\"\n",
    "region_picture_path = \"/data4/wangpengxiao/zalando_region_picture\"\n",
    "random_crop_img_path = glob.glob(osp.join(random_crop_path,'*.jpg')) \n",
    "random_crop_img_path = sorted(random_crop_img_path)\n",
    "\n",
    "region_img_path = glob.glob(osp.join(region_picture_path,'*.jpg')) \n",
    "region_img_path = sorted(region_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_paste_patch_img(ori_img, patch_img):\n",
    "\n",
    "    paste_x = np.random.randint(0, ori_img.size[0] - patch_img.size[0])\n",
    "    paste_y = np.random.randint(0, ori_img.size[1] - patch_img.size[1])\n",
    "    rotate_angle = np.random.randint(1, 359)\n",
    "    resize_x = np.random.randint(64, 384)\n",
    "    resize_y = np.random.randint(64, 384)\n",
    "    patch_img = patch_img.resize((resize_x,resize_y))\n",
    "    tem = ori_img.copy()\n",
    "    tem.paste(patch_img.rotate(rotate_angle),(paste_x,paste_y))\n",
    "    tem = np.array(tem)\n",
    "    ori_img = np.array(ori_img)\n",
    "#     for i in range(ori_img.shape[0]):\n",
    "#         for j in range(ori_img.shape[1]):\n",
    "#             if (tem[i,j,:] == np.array([0,0,0])).all():\n",
    "#                 tem[i,j,:] = ori_img[i,j,:]\n",
    "    coordinate = np.where(tem == np.array([0,0,0]))\n",
    "    for i in range(len(coordinate[0])):\n",
    "        tem[coordinate[0][i],coordinate[1][i],:] = ori_img[coordinate[0][i],coordinate[1][i],:]\n",
    "    ori_img = np.array(tem)\n",
    "    ori_img = Image.fromarray(ori_img)\n",
    "#     plt.imshow(ori_img)\n",
    "    \n",
    "    return ori_img\n",
    "\n",
    "\n",
    "def Random_paste_region_img(ori_img, region_img):\n",
    "\n",
    "    paste_x = np.random.randint(0, ori_img.size[0] - patch_img.size[0])\n",
    "    paste_y = np.random.randint(0, ori_img.size[1] - patch_img.size[1])\n",
    "    rotate_angle = np.random.randint(1, 359)\n",
    "    resize_x = np.random.randint(64, 384)\n",
    "    resize_y = np.random.randint(64, 384)\n",
    "    region_img = region_img.resize((resize_x,resize_y))\n",
    "    tem = ori_img.copy()\n",
    "    tem.paste(region_img.rotate(rotate_angle),(paste_x,paste_y))\n",
    "    tem = np.array(tem)\n",
    "    ori_img = np.array(ori_img)\n",
    "#     for i in range(ori_img.shape[0]):\n",
    "#         for j in range(ori_img.shape[1]):\n",
    "#             if (tem[i,j,:] == np.array([0,0,0])).all():\n",
    "#                 tem[i,j,:] = ori_img[i,j,:]\n",
    "    coordinate = np.where(tem == np.array([0,0,0]))\n",
    "    for i in range(len(coordinate[0])):\n",
    "        tem[coordinate[0][i],coordinate[1][i],:] = ori_img[coordinate[0][i],coordinate[1][i],:]\n",
    "    ori_img = np.array(tem)\n",
    "    ori_img = Image.fromarray(ori_img)\n",
    "#     plt.imshow(ori_img)\n",
    "    \n",
    "    return ori_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# ori_img = Image.open(source_img_path[0])\n",
    "step_1_path = '/data4/wangpengxiao/zalando_step_1'\n",
    "for path in tqdm(source_img_path):\n",
    "    ori_img = Image.open(path)\n",
    "    patch_num = np.random.randint(4, 12)\n",
    "    region_num = np.random.randint(4, 12)\n",
    "    for i in range(patch_num):\n",
    "        patch_img = Image.open(random.choice(random_crop_img_path))\n",
    "        ori_img = Random_paste_patch_img(ori_img, patch_img)\n",
    "    for i in range(region_num):\n",
    "        region_img = Image.open(random.choice(region_img_path))\n",
    "        ori_img = Random_paste_region_img(ori_img, region_img)\n",
    "\n",
    "    ori_img.save(osp.join(step_1_path, osp.basename(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_img.save('aaa.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_img = np.array(ori_img)\n",
    "c = np.where(ori_img == np.array([246,246,246]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
